{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pymilvus.model.sparse.bm25.tokenizers import build_default_analyzer\n",
    "from pymilvus.model.sparse import BM25EmbeddingFunction\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pymilvus import model\n",
    "from pymilvus import MilvusClient, Collection, connections, DataType, CollectionSchema, FieldSchema\n",
    "import numpy as np\n",
    "import json\n",
    "from FlagEmbedding import FlagReranker\n",
    "from pymilvus.model.reranker import BGERerankFunction\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "* **get_bm25_model**      -> BM25 모델 Load 함수\n",
    "* **get_reranker_model**  -> BGEM3 reranker 모델 Load 함수\n",
    "* **save_to_tsv**         -> 추론 파일 저장 함수\n",
    "* **get_bm25_result**     -> BM25 모델 추론 결과 출력 함수\n",
    "* **get_reranker_result** -> Reranker 모델 추론 결과 출력 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 모델 Load\n",
    "def get_bm25_model(model_path:str = \"./files/bm25_msmarco_v1.json\",\n",
    "                   analyzer_language:str = \"en\"):\n",
    "    analyzer = build_default_analyzer(language=analyzer_language)\n",
    "    bm25_ef = BM25EmbeddingFunction(analyzer)\n",
    "    bm25_ef.load(model_path)\n",
    "    return bm25_ef\n",
    "\n",
    "# BGE Reranker 모델 Load\n",
    "def get_reranker_model(model_path:str = \"./models/kw_3_easy_train\",\n",
    "                       device:str = \"cuda:0\"):\n",
    "    bge_rf = BGERerankFunction(\n",
    "        model_name=model_path,\n",
    "        device=device,\n",
    "        batch_size=32,\n",
    "    )\n",
    "    return bge_rf\n",
    "\n",
    "# 검색 result를 tsv 형태로 저장\n",
    "def save_to_tsv(result, output_path):\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(\"Successfully Saved!\")\n",
    "    \n",
    "\n",
    "def get_bm25_result(client, query, error_handle, top_n = 100):\n",
    "\n",
    "    # query가 에러났을 때\n",
    "    if error_handle:\n",
    "        query_embeddings = bm25_ef.encode_queries([query + \"this query is dummy\"])\n",
    "\n",
    "        res = client.search(\n",
    "            collection_name=\"msmarco_bm25\",  # target collection\n",
    "            data=query_embeddings, \n",
    "            limit=100,  # number of returned entities\n",
    "            output_fields=[\"pid\",\"text\"],  # specifies fields to be returned\n",
    "            anns_field=\"sparse_vector\",\n",
    "            )\n",
    "\n",
    "        candidate_pids = [entity[\"entity\"][\"pid\"] for entity in res[0]]\n",
    "        candidate_passages = [entity[\"entity\"][\"text\"] for entity in res[0]]\n",
    "        \n",
    "    # query가 정상일 때\n",
    "    else:\n",
    "        query_embeddings = bm25_ef.encode_queries([query])\n",
    "\n",
    "        res = client.search(\n",
    "            collection_name=\"msmarco_bm25\",  # target collection\n",
    "            data=query_embeddings, \n",
    "            limit=100,  # number of returned entities\n",
    "            output_fields=[\"pid\",\"text\"],  # specifies fields to be returned\n",
    "            anns_field=\"sparse_vector\",\n",
    "            )\n",
    "\n",
    "        candidate_pids = [entity[\"entity\"][\"pid\"] for entity in res[0]]\n",
    "        candidate_passages = [entity[\"entity\"][\"text\"] for entity in res[0]]\n",
    "\n",
    "    return candidate_pids, candidate_passages\n",
    "\n",
    "def get_reranker_result(query, candidate_passages, top_n = 100):\n",
    "    top_k = bge_rf(\n",
    "            query=query,\n",
    "            documents=candidate_passages,\n",
    "            top_k=top_n,\n",
    "        )\n",
    "    return top_k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load\n",
    "* dataset -> MSMARCO Passage Ranking <Dev> Dataset\n",
    "* testset -> MSMARCO Passage Ranking <Dev>'s 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_qid :  1266\n"
     ]
    }
   ],
   "source": [
    "# MSMARCO Query\n",
    "unique_query = pd.read_csv('./data/unique_query.csv')\n",
    "\n",
    "# Test Set에 대한 Ground Truth\n",
    "test_qrels = pd.read_csv(\"./data/test_qrels.tsv\", sep='\\t', names=['qid', 'r', 'pid', 'l'])\n",
    "\n",
    "# Test Set에 대한 qid 추출\n",
    "test_qid = test_qrels[\"qid\"].tolist()\n",
    "\n",
    "# print(\"passages : \", len(msmarco_dev_passages))\n",
    "print(\"test_qid : \", len(set(test_qid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25\n",
    "bm25_ef = get_bm25_model()\n",
    "\n",
    "# BGE Reranker\n",
    "bge_rf = get_reranker_model(model_path=\"./models/kw_3_easy_train\", device=\"cuda:0\") # finetuning 한 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_list = [unique_query[unique_query[\"qid\"] == qid_i][\"query\"].tolist()[0] for qid_i in test_qid]\n",
    "top_n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve\n",
    "* 1차 retriever -> Milvus/BM25\n",
    "* 2차 retriever -> BAAI/bge-reranker-v2-m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorDB에 클라이언트 연결\n",
    "client = MilvusClient()\n",
    "client.load_collection(\"msmarco_bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1324/1324 [05:47<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 6분 소요\n",
    "result = []\n",
    "\n",
    "for i in tqdm(range(len(test_query_list))):\n",
    "    qid = test_qid[i]\n",
    "    query = test_query_list[i]\n",
    "\n",
    "    try:\n",
    "        candidate_pids, candidate_passages = get_bm25_result(client, query, False, top_n)\n",
    "        top_k = get_reranker_result(query, candidate_passages)\n",
    "        for n,i in enumerate(top_k):\n",
    "                result.append([qid, candidate_pids[i.index], n+1])\n",
    "    except:\n",
    "        candidate_pids, candidate_passages = get_bm25_result(client, query, True, top_n)\n",
    "        top_k = get_reranker_result(query, candidate_passages)   \n",
    "        for n,i in enumerate(top_k):\n",
    "                result.append([qid, candidate_pids[i.index], n+1])\n",
    "\n",
    "output_path = \"./result/bm25_reranker.tsv\"\n",
    "\n",
    "save_to_tsv(result, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRR@100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################\n",
      "# MRR @100: 0.3914833242741064 #\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "!python ms_marco_eval.py \\\n",
    "./data/test_qrels.tsv \\\n",
    "./result/bm25_reranker_collection.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
