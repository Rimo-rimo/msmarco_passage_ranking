{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pymilvus.model.sparse.bm25.tokenizers import build_default_analyzer\n",
    "from pymilvus.model.sparse import BM25EmbeddingFunction\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pymilvus import model\n",
    "from pymilvus import MilvusClient, Collection, connections, DataType, CollectionSchema, FieldSchema\n",
    "import numpy as np\n",
    "import json\n",
    "from FlagEmbedding import FlagReranker\n",
    "from pymilvus.model.reranker import BGERerankFunction\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 모델 Load\n",
    "def get_bm25_model(model_path:str = \"./files/bm25_msmarco_v1.json\",\n",
    "                   analyzer_language:str = \"en\"):\n",
    "    analyzer = build_default_analyzer(language=analyzer_language)\n",
    "    bm25_ef = BM25EmbeddingFunction(analyzer)\n",
    "    bm25_ef.load(model_path)\n",
    "    return bm25_ef\n",
    "\n",
    "# BGE Reranker 모델 Load\n",
    "def get_reranker_model(model_path:str = \"BAAI/bge-reranker-v2-m3\",\n",
    "                       device:str = \"cuda:0\"):\n",
    "    bge_rf = BGERerankFunction(\n",
    "        model_name=model_path,\n",
    "        device=device,\n",
    "        batch_size=32,\n",
    "    )\n",
    "    return bge_rf\n",
    "\n",
    "# 검색 result를 tsv 형태로 저장\n",
    "def save_to_tsv(result, output_path):\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load\n",
    "* dataset -> MSMARCO Passage Ranking <Dev> Dataset\n",
    "* testset -> MSMARCO Passage Ranking <Dev>'s 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passages :  3895239\n",
      "test_qid :  1324\n"
     ]
    }
   ],
   "source": [
    "# MSMARCO Dev dataset\n",
    "msmarco_dev = pd.read_csv(\"./data/top1000_dev.tsv\", sep='\\t', names=['qid', 'pid', 'query', 'passage'])\n",
    "\n",
    "# MSMARCO Query\n",
    "unique_query = pd.read_csv('/home/livin/rimo/llm/msmarco/notebook/unique_query.csv')\n",
    "\n",
    "# Passage 추출 (중복된 Passage는 제거)\n",
    "msmarco_dev_passages = msmarco_dev[\"passage\"].unique().tolist()\n",
    "\n",
    "# Pid 추출 (중복된 Pid는 제거)\n",
    "msmarco_dev_pids = msmarco_dev[\"pid\"].unique().tolist()\n",
    "\n",
    "# Test Set에 대한 Ground Truth\n",
    "test_qrels = pd.read_csv(\"./data/test_qrels.tsv\", sep='\\t', names=['qid', 'r', 'pid', 'l'])\n",
    "\n",
    "# Test Set에 대한 qid 추출\n",
    "test_qid = test_qrels[\"qid\"].tolist()\n",
    "\n",
    "print(\"passages : \", len(msmarco_dev_passages))\n",
    "print(\"test_qid : \", len(set(test_qid)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25\n",
    "bm25_ef = get_bm25_model()\n",
    "\n",
    "# BGE Reranker\n",
    "bge_rf = get_reranker_model(model_path=\"./models/kw_3_easy_train\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25_docs_embedding Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 모델을 활용한 passage들의 imbedding 불러오기\n",
    "with open(\"./files/bm25_docs_embeddings.pickle\", \"rb\") as handle:\n",
    "    docs_embeddings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test set load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "pid_array = np.array(msmarco_dev_pids)\n",
    "passages_array = np.array(msmarco_dev_passages)\n",
    "test_query_list = [unique_query[unique_query[\"qid\"] == qid_i][\"query\"].tolist()[0] for qid_i in test_qid]\n",
    "query_embeddings = bm25_ef.encode_queries(test_query_list)\n",
    "cosine_similarities = cosine_similarity(docs_embeddings, query_embeddings)#.flatten()\n",
    "top_n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve\n",
    "* 1차 retriever -> Milvus/BM25\n",
    "* 2차 retriever -> BAAI/bge-reranker-v2-m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1324 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# 24분 소요\n",
    "for i in tqdm(range(len(test_query_list))):\n",
    "    qid = test_qid[i]\n",
    "    query = test_query_list[i]\n",
    "    \n",
    "    candidate_idxs = np.argsort(cosine_similarities[:,i])[-100:][::-1]\n",
    "    candidate_pids = pid_array[candidate_idxs]\n",
    "    candidate_passages = passages_array[candidate_idxs]\n",
    "\n",
    "    top_k = bge_rf(\n",
    "                query=query,\n",
    "                documents=candidate_passages,\n",
    "                top_k=100,\n",
    "            )\n",
    "    for n,i in enumerate(top_k):\n",
    "            result.append([qid, candidate_pids[i.index], n+1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "save_to_tsv(result, \"./result/bm25_reranker_.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1324 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "pid_array = np.array(msmarco_dev_pids)\n",
    "passages_array = np.array(msmarco_dev_passages)\n",
    "top_n = 100\n",
    "\n",
    "for i in tqdm(range(len(test_qid))):\n",
    "    try:\n",
    "        # qid, query 추출\n",
    "        qid = test_qid[i]\n",
    "        query = unique_query[unique_query[\"qid\"] == qid][\"query\"].tolist()[0]\n",
    "\n",
    "        # BM25를 활용한 1차 retrieve\n",
    "        query_embeddings = bm25_ef.encode_queries([query]) # query 임베딩\n",
    "        cosine_similarities = cosine_similarity(docs_embeddings, query_embeddings).flatten() # query와 passage간의 유사도 계산\n",
    "        candidate_idxs = np.argsort(cosine_similarities)[-100:][::-1] # top 100 indexes 추출\n",
    "\n",
    "        # BM25 검색 결과에 대한 pids와 passages 추출\n",
    "        candidate_pids = pid_array[candidate_idxs]\n",
    "        candidate_passages = passages_array[candidate_idxs]\n",
    "\n",
    "        # reranker를 활용한 2차 retrieve\n",
    "        top_k = bge_rf(\n",
    "                query=query,\n",
    "                documents=candidate_passages,\n",
    "                top_k=100,\n",
    "            )\n",
    "        \n",
    "        # [qid, pid, rank] format으로 저장\n",
    "        for n,i in enumerate(top_k):\n",
    "            result.append([qid, candidate_pids[i.index], n+1])\n",
    "        break\n",
    "    except:\n",
    "        print(qid)\n",
    "\n",
    "\n",
    "save_to_tsv(result, \"./result/bm25_reranker.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118448, 'define body muscular endurance')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
