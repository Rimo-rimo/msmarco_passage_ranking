{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from pymilvus import model\n",
    "from pymilvus import MilvusClient, Collection, connections, DataType, CollectionSchema, FieldSchema\n",
    "from pymilvus.model.reranker import BGERerankFunction\n",
    "\n",
    "from FlagEmbedding import FlagReranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 모델 Load\n",
    "def get_embedding_model(model_name = \"BAAI/bge-m3\", batch_size= 64, device = \"cuda:0\"):\n",
    "    bge_m3_ef = model.hybrid.BGEM3EmbeddingFunction(\n",
    "        model_name= model_name,\n",
    "        batch_size = batch_size,\n",
    "        device = device,\n",
    "        return_dense = True,\n",
    "        return_sparse = False,\n",
    "        return_colbert_vecs = False,\n",
    "    )\n",
    "    return bge_m3_ef\n",
    "\n",
    "# BGE Reranker 모델 Load\n",
    "def get_reranker_model(model_path = \"./models/kw_3_easy_train\",\n",
    "                       device = \"cuda:0\"):\n",
    "    bge_rf = BGERerankFunction(\n",
    "        model_name=model_path,\n",
    "        device=device,\n",
    "        batch_size=32,\n",
    "    )\n",
    "    return bge_rf\n",
    "\n",
    "# 검색 result를 tsv 형태로 저장\n",
    "def save_to_tsv(result, output_path):\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(\"Successfully Saved!\")\n",
    "\n",
    "def get_vector_search_result(client, query, top_n = 100):\n",
    "\n",
    "    query_vectors = bge_m3_ef.encode_queries([query])[\"dense\"]\n",
    "    candidate = client.search(\n",
    "        collection_name=\"msmarco_bgem3\",  # target collection\n",
    "        data=query_vectors,  # query vectors\n",
    "        limit=top_n,  # number of returned entities\n",
    "        output_fields=[\"pid\",\"text\"],\n",
    "        anns_field=\"dense_vector\"\n",
    "    )\n",
    "    candidate_passages = [i[\"entity\"][\"text\"] for i in candidate[0]]\n",
    "    candidate_pids = np.array([i[\"entity\"][\"pid\"] for i in candidate[0]])\n",
    "\n",
    "    return candidate_pids, candidate_passages\n",
    "\n",
    "def get_reranker_result(query, candidate_passages, top_n = 100):\n",
    "    top_k = bge_rf(\n",
    "            query=query,\n",
    "            documents=candidate_passages,\n",
    "            top_k=top_n,\n",
    "        )\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_query = pd.read_csv('./data/unique_query.csv')\n",
    "test_qrels = pd.read_csv(\"./data/test_qrels.tsv\", sep='\\t', names=['qid', 'r', 'pid', 'l'])\n",
    "test_qid = test_qrels[\"qid\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ee71ec62db40899d7d716a98357993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BGE-M3\n",
    "bge_m3_ef = get_embedding_model()\n",
    "\n",
    "# BGE Reranker\n",
    "bge_rf = get_reranker_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorDB에 클라이언트 연결\n",
    "client = MilvusClient()\n",
    "client.load_collection(\"msmarco_bgem3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 192/1324 [02:27<14:19,  1.32it/s]"
     ]
    }
   ],
   "source": [
    "# 19분 소요\n",
    "result = []\n",
    "error_list = []\n",
    "\n",
    "for i in tqdm(range(len(test_qid))):\n",
    "    try:\n",
    "        qid = test_qid[i]\n",
    "        query = unique_query[unique_query[\"qid\"] == qid][\"query\"].tolist()[0]\n",
    "        candidate_pids, candidate_passages = get_vector_search_result(client, query, 100)\n",
    "        top_k = get_reranker_result(query, candidate_passages, 100)\n",
    "\n",
    "        for n,k in enumerate(top_k):\n",
    "            result.append([qid, candidate_pids[k.index], n+1])\n",
    "\n",
    "    except:\n",
    "        error_list.append(qid)\n",
    "        print(qid)\n",
    "\n",
    "output_path = \"./result/bgem3_reranker.tsv\"\n",
    "save_to_tsv(result, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/livin/rimo/llm/MSMARCO_TEST/ms_marco_eval.py\", line 176, in <module>\n",
      "    main()\n",
      "  File \"/home/livin/rimo/llm/MSMARCO_TEST/ms_marco_eval.py\", line 170, in main\n",
      "    metrics = compute_metrics_from_files(path_to_reference, path_to_candidate)\n",
      "  File \"/home/livin/rimo/llm/MSMARCO_TEST/ms_marco_eval.py\", line 157, in compute_metrics_from_files\n",
      "    qids_to_ranked_candidate_passages = load_candidate(path_to_candidate)\n",
      "  File \"/home/livin/rimo/llm/MSMARCO_TEST/ms_marco_eval.py\", line 74, in load_candidate\n",
      "    with open(path_to_candidate,'r') as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './result/bgem3_reranker.tsv'\n"
     ]
    }
   ],
   "source": [
    "!python ms_marco_eval.py \\\n",
    "./data/test_qrels.tsv \\\n",
    "./result/bgem3_reranker.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
